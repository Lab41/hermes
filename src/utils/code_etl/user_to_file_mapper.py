#!/usr/bin/env python

"""Provides functions to convert `git log` information for a repository to JSON
suitable to read in with Spark.

Attributes:
    JSON_LINE (dict): A dictionary that stores information from `git log`. Each
        entry corresponds to the information from one line in the source file.
        The variables are as follows:
            - repo_name (str): The name of the repository.
            - author (str): The author of the commit.
            - author_mail (str): The author's email address.
            - filename (str): The name of the file.
            - edit_count (int): The number of edits (counted by commits) made
                on a file by an author.
"""

from subprocess import check_output
import json
from copy import deepcopy
from collections import Counter

# The JSON object to
JSON_LINE = {
    "repo_name": None,
    "author": None,
    "author_mail": None,
    "filename": None,
    "edit_count": None,
}


def log_block_generator():
    """Generates a set of "data blocks" using `git log`.

    Each block is the information from a single commit.

    The `--format` option is used to format the author name and email in a way
    which this code can easily parse.

    Args:
        None

    Yields:
        list: A list of the lines from the log output.
    """
    # Get the text from blame
    command = [
        'git',
        'log',
        '--format=NAME: "%aN", EMAIL: "%aE"',
        '--name-only',
    ]

    log = check_output(command)

    # Buffer the lines from the output until we find one that starts with \t,
    # indicating
    buffer = []
    for line in log.splitlines():
        if line:  # Ignore blank lines
            buffer.append(line)
        if line.startswith('NAME:'):
            yield buffer
            buffer = []


def parse_block(block, file_map):
    """Take a data block and add it to a file map.

    A file map is a dictionary with the following form:

        file_map = {
            file: [
                (name_0, email_0),
                ...
                (name_N, email_N),
            ],
            ...
        }

    Where each file in the project (even files that no longer exist) maps to a
    list of author names and author email address. There is an name/email pair
    for each commit which touched the file and so these pairs are not unique.

    A data block is a list of the form:

        data_block = [
            file_0,
            ...
            file_M,
            'NAME: "Author Name", EMAIL: "Author Email"',
        ]

    For each file in the data block, an name/email pair is added to the
    corresponding list in the file_map.

    Args:
        block (list): A data_block as described above.
        file_map (dict): A file_map as described above. An empty dictionary is
            a perfectly valid file_map. The file_map *is* modified by this
            function and is the primary "output".

    Returns:
        None (although the file_map is modified by this function)

    """
    name = None
    email = None
    files = []

    # Parse the lines of text to get the name and email of the user, as well as
    # all the files touched in the commit
    for line in block:
        if line.startswith("NAME:"):
            # The line with the name and the email have the following form:
            #
            #     NAME: "Author Name", EMAIL "Author Email"
            #     ^      ^          |________|            ^
            #     0      7            Split              -1
            #
            # Therefore we split it on '", EMAIL "' which is guaranteed to be
            # in the middle of the two values we care about, and then slice by
            # counting characters from the end, since these are also guaranteed
            # to be there.
            sline = line.split('", EMAIL: "')

            BEGINING_OF_NAME = 7
            name = sline[0][BEGINING_OF_NAME:]
            LAST_QUOTE = -1
            email = sline[1][:LAST_QUOTE]
        else:
            # Otherwise it is a file name
            files.append(line)

    # Now add the user to each file's entry in the file_map
    if name and email:
        for file in files:
            try:
                file_map[file].append((name, email))
            except KeyError:
                file_map[file] = [(name, email)]


def clean_text(text):
    """ Remove non-ascii characters from a string.

    Args:
        text (str): A string.

    Returns:
        str: A string with all characters with ord() >= 128 removed.

    """
    return ''.join([i if ord(i) < 128 else '' for i in text])


def file_map_to_json(file_map, repo_name):
    """Returns a list of JSON objects as strings containing the `git log`
    information.

    Args:
        file_map (dict): A file_map as generated by parse_block().
        repo_name (str): The name of the repository.

    Returns:
        list: A list containing strings of the JSON objects.

    """
    jsons = []
    for file in file_map:
        counter = Counter(file_map[file])
        for key, count in counter.iteritems():
            current_json = deepcopy(JSON_LINE)
            current_json["repo_name"] = repo_name
            current_json["author"] = clean_text(key[0])
            current_json["author_mail"] = clean_text(key[1])
            current_json["filename"] = file
            current_json["edit_count"] = count
            jsons.append(json.dumps(current_json))

    return jsons


def repo_to_file_map_json(repo_name):
    """Returns a list of JSON objects as strings containing the `git log`
    of the current directory.

    Args:
        repo_name (str): The name of the repository.

    Returns:
        list: A list containing strings of the JSON objects.

    """
    file_map = {}
    for block in log_block_generator():
        parse_block(block, file_map)

    return file_map_to_json(file_map, repo_name)
